{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import gensim as gs\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch import helpers\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "tknzr = TweetTokenizer()\n",
    "indexing_dataset_search = Elasticsearch(timeout=30, max_retries=10, retry_on_timeout=True)\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexing_dataset_search.indices.close(index='dataset_search')\n",
    "indexing_dataset_search.indices.put_settings(index='dataset_search', body={\"index\": {\"similarity\": {\"default\": {\"type\": \"classic\"}}}})\n",
    "indexing_dataset_search.indices.open(index='dataset_search')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elasticsearch_search(query):\n",
    "    \n",
    "    result= indexing_dataset_search.search(\n",
    "        index=\"dataset_search\", \n",
    "        body = {\n",
    "        \"_source\": [\"dataset_id\",\"dataset_title\"],\n",
    "        \"from\" : 0,\n",
    "        \"size\" : 100,\n",
    "        \"query\": {\n",
    "            \"multi_match\":{\n",
    "              \"type\": \"most_fields\",\n",
    "              \"query\":    query, \n",
    "              \"fields\": [\"dataset_title\", \"dataset_description\"] \n",
    "            }\n",
    "        }\n",
    "    })\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_data_index(query):\n",
    "    \n",
    "    datasets_index = []\n",
    "\n",
    "    result_index = elasticsearch_search(query)\n",
    "        \n",
    "    for hit in result_index['hits']['hits']:\n",
    "    \n",
    "        dataset_id = hit['_source']['dataset_id']\n",
    "        \n",
    "        dataset_title = hit['_source']['dataset_title']\n",
    "    \n",
    "        datasets_index.append(dataset_id)\n",
    "    \n",
    "    return datasets_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevance_judgments = pd.read_csv('../../data/data_search_2_e_train_qrels.txt', delimiter=\" \")\n",
    "relevance_judgments = pd.DataFrame(relevance_judgments.values, columns = [\"query_id\", \"dataset_id\", \"relevance\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevance(query_id, dataset_id):\n",
    "    \n",
    "    relevance_by_query = relevance_judgments.loc[relevance_judgments['query_id'] == query_id]\n",
    "    \n",
    "    relevance_by_dataset = relevance_by_query.loc[relevance_by_query['dataset_id'] == dataset_id]\n",
    "    \n",
    "    if relevance_by_dataset.empty:\n",
    "    \n",
    "        return 0\n",
    "    \n",
    "    else:\n",
    "    \n",
    "        relevance_jugdment = relevance_by_dataset['relevance'].values[0].replace(\"L\",\"\")\n",
    "        \n",
    "        return int(relevance_jugdment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_queries = pd.read_csv('../../data/train_queries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_queries.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_recall = []\n",
    "\n",
    "for i,row in tqdm(train_queries.iterrows()):\n",
    "    \n",
    "    query_id = row['query_id']\n",
    "    query_description = row['query_description']\n",
    "    \n",
    "    result_index = return_data_index(query_description)\n",
    "    \n",
    "    #getting the relevance score for each elasticsearch result\n",
    "    predict_relevance = []\n",
    "    \n",
    "    for dataset_id in result_index:\n",
    "        \n",
    "        value_relevance = get_relevance(query_id,dataset_id)\n",
    "    \n",
    "        predict_relevance.append(value_relevance)\n",
    "    \n",
    "    ##getting the relevant datasets for the query\n",
    "    relevance_by_query = relevance_judgments.loc[relevance_judgments['query_id'] == query_id]\n",
    "    relevant_datasets = relevance_by_query[(relevance_by_query['relevance'] == 'L2') | (relevance_by_query['relevance'] == 'L1')]\n",
    "    \n",
    "    #computing the recall\n",
    "    relevant_predict = np.count_nonzero(predict_relevance)\n",
    "    \n",
    "    correct_relevant = relevant_datasets[\"query_id\"].count()\n",
    "    \n",
    "    #print(\"predict = \"+str(relevant_predict)+\" relevant =\"+str(correct_relevant))\n",
    "    \n",
    "    if (correct_relevant != 0):\n",
    "        \n",
    "        recall = relevant_predict/correct_relevant\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        recall = 0\n",
    "        \n",
    "    result_recall.append(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(result_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
