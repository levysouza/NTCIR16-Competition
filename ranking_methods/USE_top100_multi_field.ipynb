{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import gensim as gs\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "import tensorflow_hub as hub\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "tknzr = TweetTokenizer()\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from heapq import nsmallest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_queries = pd.read_csv('../data/final_train_queries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_queries.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_index = pd.read_csv('../data/fixed_test_set_index_top50.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_index.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevance_judgments = pd.read_csv('../data/data_search_2_e_train_qrels.txt', delimiter=\" \")\n",
    "relevance_judgments = pd.DataFrame(relevance_judgments.values, columns = [\"query_id\", \"dataset_id\", \"relevance\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = hub.load(module_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevance(query_id, dataset_id):\n",
    "    \n",
    "    relevance_by_query = relevance_judgments.loc[relevance_judgments['query_id'] == query_id]\n",
    "    \n",
    "    relevance_by_dataset = relevance_by_query.loc[relevance_by_query['dataset_id'] == dataset_id]\n",
    "    \n",
    "    if relevance_by_dataset.empty:\n",
    "    \n",
    "        return 0\n",
    "    \n",
    "    else:\n",
    "    \n",
    "        relevance_jugdment = relevance_by_dataset['relevance'].values[0].replace(\"L\",\"\")\n",
    "        \n",
    "        return int(relevance_jugdment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcg_metric(relevance,k):\n",
    "    \n",
    "    dcg = 0\n",
    "    \n",
    "    for i in range(1,k+1):\n",
    "        \n",
    "        dcg = dcg + (relevance[i-1] / np.log2(i+1))\n",
    "        \n",
    "    return dcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_ndcg = []\n",
    "\n",
    "for i, row in tqdm(train_queries.iterrows()):\n",
    "\n",
    "    #current article values\n",
    "    query_id = row['query_id']\n",
    "    query_description = row['query_description']\n",
    "   \n",
    "    #embedding \n",
    "    queries_search_text = []\n",
    "    queries_search = []\n",
    "    \n",
    "    queries_search_text.append(query_description)\n",
    "    embedding_queries = embed(queries_search_text)\n",
    "    queries_search = []\n",
    "    for current_embedding in embedding_queries:\n",
    "        queries_search.append(current_embedding.numpy())\n",
    "\n",
    "    \n",
    "    #return index\n",
    "    return_index = fixed_index.loc[fixed_index['label_index'] == query_id]\n",
    "    \n",
    "\n",
    "    #creating embedding datasets title\n",
    "    dataset_index_text_title = []\n",
    "    dataset_index_title = []\n",
    "    \n",
    "    for i, row in return_index.iterrows():\n",
    "            \n",
    "            dataset_index_text_title.append(str(row['dataset_title']))\n",
    "\n",
    "    embedding_datasets = embed(dataset_index_text_title)\n",
    "\n",
    "    for current_embedding in embedding_datasets:\n",
    "        dataset_index_title.append(current_embedding.numpy())\n",
    "      \n",
    "    \n",
    "    #creating embedding datasets description\n",
    "    dataset_index_text_description = []\n",
    "    dataset_index_description = []\n",
    "    \n",
    "    for i, row in return_index.iterrows():\n",
    "            \n",
    "            dataset_index_text_description.append(str(row['dataset_description']))\n",
    "\n",
    "    embedding_datasets = embed(dataset_index_text_description)\n",
    "\n",
    "    for current_embedding in embedding_datasets:\n",
    "        dataset_index_description.append(current_embedding.numpy())\n",
    "        \n",
    "    \n",
    "    #creating embedding datasets tags\n",
    "    dataset_index_text_tags = []\n",
    "    dataset_index_tags = []\n",
    "    \n",
    "    for i, row in return_index.iterrows():\n",
    "            \n",
    "            dataset_index_text_tags.append(str(row['dataset_tags']))\n",
    "\n",
    "    embedding_datasets = embed(dataset_index_text_tags)\n",
    "\n",
    "    for current_embedding in embedding_datasets:\n",
    "        dataset_index_tags.append(current_embedding.numpy())\n",
    "    \n",
    "    \n",
    "    #getting the distances\n",
    "    distance_vector_title = pairwise_distances(queries_search, dataset_index_title, metric='cosine')\n",
    "    distance_vector_description = pairwise_distances(queries_search, dataset_index_description, metric='cosine')\n",
    "    distance_vector_tags = pairwise_distances(queries_search, dataset_index_tags, metric='cosine')\n",
    "    \n",
    "    \n",
    "    #creating the final dataframe for datasets\n",
    "    ranked_datasets_model = []\n",
    "    \n",
    "    for i in range(0,len(distance_vector_title[0])):\n",
    "        \n",
    "        distance_title = distance_vector_title[0][i]\n",
    "        distance_description = distance_vector_description[0][i]\n",
    "        distance_tags = distance_vector_tags[0][i]\n",
    "        distance_mean = (distance_title+distance_description+distance_tags)/3\n",
    "\n",
    "        ranked_datasets_model.append([return_index.iloc[i]['dataset_id'],return_index.iloc[i]['dataset_title'],distance_title,distance_description,distance_tags, distance_mean]) \n",
    "\n",
    "    data_frame = pd.DataFrame(ranked_datasets_model, columns = ['dataset_id', 'dataset_title','dataset_ranking_title','dataset_ranking_description','dataset_ranking_tags','mean_distance']) \n",
    "    data_frame_sorting = data_frame.sort_values('mean_distance')\n",
    "    selected_top = data_frame_sorting.head(10)\n",
    "    \n",
    "    #getting true relevance\n",
    "    \n",
    "    true_relevance = []\n",
    "    \n",
    "    relevance_by_query = relevance_judgments.loc[relevance_judgments['query_id'] == query_id]\n",
    "    #sorting and reading the top10\n",
    "    ideal_relevance = relevance_by_query.sort_values(by=['relevance'], ascending=False).head(10)\n",
    "    \n",
    "    for i, row in ideal_relevance.iterrows():\n",
    "        \n",
    "        dataset_id = row['dataset_id']\n",
    "        value_relevance = int(row['relevance'].replace(\"L\",\"\"))\n",
    "        \n",
    "        true_relevance.append(value_relevance)\n",
    "\n",
    "    \n",
    "    \n",
    "    #getting the predicted relevance\n",
    "    predict_relevance = []\n",
    "    \n",
    "    for i,row in selected_top.iterrows():\n",
    "        \n",
    "        value_relevance = get_relevance(query_id,row['dataset_id'])\n",
    "    \n",
    "        predict_relevance.append(value_relevance)\n",
    "    \n",
    "    #computing NDCG\n",
    "    dcg = dcg_metric(predict_relevance, len(predict_relevance))\n",
    "    idcg = dcg_metric(true_relevance, len(true_relevance))\n",
    "    \n",
    "    if (idcg != 0):\n",
    "    \n",
    "        ndcg = dcg / idcg\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        count = count + 1\n",
    "        \n",
    "        ndcg = 0\n",
    "    \n",
    "    result_ndcg.append(ndcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(result_ndcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
