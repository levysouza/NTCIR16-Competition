{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import gensim as gs\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch import helpers\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "tknzr = TweetTokenizer()\n",
    "indexing_dataset_search = Elasticsearch(timeout=30, max_retries=10, retry_on_timeout=True)\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexing_dataset_search.indices.close(index='dataset_search')\n",
    "indexing_dataset_search.indices.put_settings(index='dataset_search', body={\"index\": {\"similarity\": {\"default\": {\"type\": \"BM25\"}}}})\n",
    "indexing_dataset_search.indices.open(index='dataset_search')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elasticsearch_search(query):\n",
    "    \n",
    "    result= indexing_dataset_search.search(\n",
    "        index=\"dataset_search\", \n",
    "        body = {\n",
    "        \"_source\": [\"dataset_id\",\"dataset_title\"],\n",
    "        \"from\" : 0,\n",
    "        \"size\" : 20,\n",
    "        \"query\": {\n",
    "            \"multi_match\":{\n",
    "              \"type\": \"most_fields\",\n",
    "              \"query\":    query, \n",
    "              \"fields\": [\"dataset_title\",\"dataset_description\"] \n",
    "            }\n",
    "        }\n",
    "    })\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_data_index(query):\n",
    "    \n",
    "    datasets_index = []\n",
    "\n",
    "    result_index = elasticsearch_search(query)\n",
    "        \n",
    "    for hit in result_index['hits']['hits']:\n",
    "    \n",
    "        dataset_id = hit['_source']['dataset_id']\n",
    "        \n",
    "        dataset_title = hit['_source']['dataset_title']\n",
    "    \n",
    "        datasets_index.append(dataset_id)\n",
    "    \n",
    "    return datasets_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevance_judgments = pd.read_csv('../data/data_search_2_e_train_qrels.txt', delimiter=\" \")\n",
    "relevance_judgments = pd.DataFrame(relevance_judgments.values, columns = [\"query_id\", \"dataset_id\", \"relevance\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevance(query_id, dataset_id):\n",
    "    \n",
    "    relevance_by_query = relevance_judgments.loc[relevance_judgments['query_id'] == query_id]\n",
    "    \n",
    "    relevance_by_dataset = relevance_by_query.loc[relevance_by_query['dataset_id'] == dataset_id]\n",
    "    \n",
    "    if relevance_by_dataset.empty:\n",
    "    \n",
    "        return 0\n",
    "    \n",
    "    else:\n",
    "    \n",
    "        relevance_jugdment = relevance_by_dataset['relevance'].values[0].replace(\"L\",\"\")\n",
    "        \n",
    "        return int(relevance_jugdment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcg_metric(relevance,k):\n",
    "    \n",
    "    dcg = 0\n",
    "    \n",
    "    for i in range(1,k+1):\n",
    "        \n",
    "        dcg = dcg + (relevance[i-1] / np.log2(i+1))\n",
    "        \n",
    "    return dcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_queries = pd.read_csv('../data/train_queries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_queries.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_ndcg = []\n",
    "count = 0\n",
    "hard_queries = []\n",
    "\n",
    "for i,row in tqdm(train_queries.iterrows()):\n",
    "    \n",
    "    query_id = row['query_id']\n",
    "    query_description = row['query_description']\n",
    "    \n",
    "    result_index = return_data_index(query_description)\n",
    "    \n",
    "    #getting the relevance score for each elasticsearch result\n",
    "    \n",
    "    predict_relevance = []\n",
    "    \n",
    "    for dataset_id in result_index:\n",
    "        \n",
    "        value_relevance = get_relevance(query_id,dataset_id)\n",
    "    \n",
    "        predict_relevance.append(value_relevance)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #getting true relevance\n",
    "    \n",
    "    true_relevance = []\n",
    "    \n",
    "    relevance_by_query = relevance_judgments.loc[relevance_judgments['query_id'] == query_id]\n",
    "    #sorting and reading the top10\n",
    "    ideal_relevance = relevance_by_query.sort_values(by=['relevance'], ascending=False).head(10)\n",
    "    \n",
    "    for i, row in ideal_relevance.iterrows():\n",
    "        \n",
    "        dataset_id = row['dataset_id']\n",
    "        value_relevance = int(row['relevance'].replace(\"L\",\"\"))\n",
    "        \n",
    "        true_relevance.append(value_relevance)\n",
    "   \n",
    "\n",
    "\n",
    "    #computing metrics\n",
    "    dcg = dcg_metric(predict_relevance, len(predict_relevance))\n",
    "    idcg = dcg_metric(true_relevance, len(true_relevance))\n",
    "    \n",
    "    if (idcg != 0):\n",
    "    \n",
    "        ndcg = dcg / idcg\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        count = count + 1\n",
    "        \n",
    "        ndcg = 0\n",
    "    \n",
    "    result_ndcg.append(ndcg)\n",
    "\n",
    "    if ndcg == 0:\n",
    "        \n",
    "        hard_queries.append([query_id,query_description])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(result_ndcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
